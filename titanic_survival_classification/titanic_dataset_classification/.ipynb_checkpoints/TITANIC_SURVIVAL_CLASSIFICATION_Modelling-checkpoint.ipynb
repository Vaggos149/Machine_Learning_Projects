{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('D:/KAGGLE COMPETITIONS/Titanic/4. Analysis/train_after_feature_encoding.csv')\n",
    "labels=pd.read_csv('D:/KAGGLE COMPETITIONS/Titanic/4. Analysis/labels.csv',header=None,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Setting Seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing and Inspecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data are already scaled, so we just need to feed some classifiers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Deck_B</th>\n",
       "      <th>Deck_C</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_T</th>\n",
       "      <th>Deck_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.293286</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510737</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.347649</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396963</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728187</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021473</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361239</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.021731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.184561</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048655</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.032596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.782550</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266105</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.524327</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.184561</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021473</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.056848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.396963</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.415602</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035134</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396963</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass       Age  SibSp     Parch      Fare  Sex_female  Sex_male  \\\n",
       "0      1.0  0.293286  0.125  0.000000  0.014151         0.0       1.0   \n",
       "1      0.0  0.510737  0.125  0.000000  0.139136         1.0       0.0   \n",
       "2      1.0  0.347649  0.000  0.000000  0.015469         1.0       0.0   \n",
       "3      0.0  0.469965  0.125  0.000000  0.103644         1.0       0.0   \n",
       "4      1.0  0.469965  0.000  0.000000  0.015713         0.0       1.0   \n",
       "5      1.0  0.396963  0.000  0.000000  0.016510         0.0       1.0   \n",
       "6      0.0  0.728187  0.000  0.000000  0.101229         0.0       1.0   \n",
       "7      1.0  0.021473  0.375  0.166667  0.041136         0.0       0.0   \n",
       "8      1.0  0.361239  0.000  0.333333  0.021731         1.0       0.0   \n",
       "9      0.5  0.184561  0.125  0.000000  0.058694         0.0       0.0   \n",
       "10     1.0  0.048655  0.125  0.166667  0.032596         0.0       0.0   \n",
       "11     0.0  0.782550  0.000  0.000000  0.051822         1.0       0.0   \n",
       "12     1.0  0.266105  0.000  0.000000  0.015713         0.0       1.0   \n",
       "13     1.0  0.524327  0.125  0.833333  0.061045         0.0       1.0   \n",
       "14     1.0  0.184561  0.000  0.000000  0.015330         0.0       0.0   \n",
       "15     0.5  0.741778  0.000  0.000000  0.031230         1.0       0.0   \n",
       "16     1.0  0.021473  0.500  0.166667  0.056848         0.0       0.0   \n",
       "17     0.5  0.396963  0.000  0.000000  0.025374         0.0       1.0   \n",
       "18     1.0  0.415602  0.125  0.000000  0.035134         1.0       0.0   \n",
       "19     1.0  0.396963  0.000  0.000000  0.014102         1.0       0.0   \n",
       "\n",
       "    Embarked_Q  Embarked_S  Deck_B  Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  \\\n",
       "0          0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1          0.0         0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "2          0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3          0.0         1.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "4          0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5          1.0         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "6          0.0         1.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "7          0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "8          0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9          0.0         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "10         0.0         1.0     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "11         0.0         1.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "12         0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "13         0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "14         0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "15         0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "16         1.0         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "17         0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "18         0.0         1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "19         0.0         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "    Deck_T  Deck_U  \n",
       "0      0.0     1.0  \n",
       "1      0.0     0.0  \n",
       "2      0.0     1.0  \n",
       "3      0.0     0.0  \n",
       "4      0.0     1.0  \n",
       "5      0.0     1.0  \n",
       "6      0.0     0.0  \n",
       "7      0.0     1.0  \n",
       "8      0.0     1.0  \n",
       "9      0.0     1.0  \n",
       "10     0.0     0.0  \n",
       "11     0.0     0.0  \n",
       "12     0.0     1.0  \n",
       "13     0.0     1.0  \n",
       "14     0.0     1.0  \n",
       "15     0.0     1.0  \n",
       "16     0.0     1.0  \n",
       "17     0.0     1.0  \n",
       "18     0.0     1.0  \n",
       "19     0.0     1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1\n",
       "0    \n",
       "0   0\n",
       "1   1\n",
       "2   1\n",
       "3   1\n",
       "4   0\n",
       "5   0\n",
       "6   0\n",
       "7   0\n",
       "8   1\n",
       "9   1\n",
       "10  1\n",
       "11  1\n",
       "12  0\n",
       "13  0\n",
       "14  0\n",
       "15  1\n",
       "16  0\n",
       "17  1\n",
       "18  0\n",
       "19  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(data,labels,test_size=0.3,stratify=labels,random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_neighbors {'n_neighbors': 5}\n",
      " \n",
      " \n",
      "Best score is 0.8314606741573034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid={'n_neighbors':np.arange(1,10)} \n",
    "\n",
    "knn_temp=KNeighborsClassifier()                                      \n",
    "knn_cv=GridSearchCV(knn_temp,param_grid,cv=3)\n",
    "\n",
    "_=knn_cv.fit(X_train,y_train)                                                 \n",
    "\n",
    "print('Best n_neighbors '+str(knn_cv.best_params_),end='\\n \\n \\n')          \n",
    "\n",
    "print('Best score is '+ str(knn_cv.best_score_))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So, the best number of neighbours is 5....We fit a KNN with 5 neighbours\n",
    "\n",
    "* We also perform cross validation to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832      0.872      0.824      0.832      0.76422764]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn_cross_val=KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn_cross_val_scores = cross_val_score(knn_cross_val, X_train, y_train, cv=5)\n",
    "\n",
    "print(knn_cross_val_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pretty Consistent overall for cross validation....\n",
    "\n",
    "* We will now fit the classifier on whole X_train,y_train and test on X_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluating on X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "predictions=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       165\n",
      "           1       0.70      0.73      0.71       102\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.77      0.77      0.77       267\n",
      "weighted avg       0.78      0.78      0.78       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[134  31]\n",
      " [ 28  74]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC_AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8313131313131312\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba=knn.predict_proba(X_test)[:,1]\n",
    "\n",
    "knn_roc_auc_score=roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "print(knn_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8491171749598716\n",
      "{'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=SEED, n_jobs=-1)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10, 12, 16], \n",
    "              \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "#print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.1565961 , 0.19894306, 0.62008262, 1.22296834, 1.80116932,\n",
      "       0.1813736 , 0.22138278, 0.6773231 , 1.2681636 , 1.67963346,\n",
      "       0.1770951 , 0.17474016, 0.67548633, 1.37097708, 1.77173559,\n",
      "       0.14603353, 0.22571747, 0.81751855, 1.02974486, 1.57763902,\n",
      "       0.14403311, 0.17397801, 0.71674411, 1.19594407, 1.81591296,\n",
      "       0.15626073, 0.18230422, 0.7501862 , 1.20854998, 1.7346278 ,\n",
      "       0.14063819, 0.19271803, 0.7760946 , 1.13942973, 1.62275894,\n",
      "       0.15105216, 0.18272861, 0.65481408, 1.21258481, 1.73827497,\n",
      "       0.14236577, 0.19539611, 0.7551144 , 1.20150391, 1.57297254,\n",
      "       0.1499393 , 0.19671019, 0.69146713, 1.22998961, 1.63811501,\n",
      "       0.14428512, 0.19272161, 0.74540965, 1.17759124, 1.59230741,\n",
      "       0.14063462, 0.18230343, 0.73372173, 1.15534782, 1.56868815,\n",
      "       0.14636676, 0.1873757 , 0.71849585, 1.13868078, 1.61375109,\n",
      "       0.14870071, 0.1867307 , 0.64156747, 1.17118621, 1.64241982,\n",
      "       0.14063438, 0.20357839, 0.73183195, 1.22698196, 1.6755077 ,\n",
      "       0.14705261, 0.20678004, 0.72439623, 1.51634518, 1.91844304,\n",
      "       0.18204133, 0.25256713, 0.84304579, 1.53002477, 1.73582737,\n",
      "       0.15217924, 0.18953133, 0.78081687, 1.50675201, 1.95141617,\n",
      "       0.14554318, 0.27354161, 0.84566092, 1.44049986, 2.07070335,\n",
      "       0.1569821 , 0.22633147, 0.82315135, 1.37117982, 1.95531241,\n",
      "       0.16949145, 0.20804405, 0.72849933, 1.37297773, 1.72672478,\n",
      "       0.14803282, 0.21571533, 0.71649623, 1.30562957, 1.53887407,\n",
      "       0.14569974, 0.20437837, 0.69018133, 1.33984359, 1.68861993,\n",
      "       0.14370251, 0.19790975, 0.72183752, 1.13955919, 1.65753476,\n",
      "       0.1470329 , 0.19804287, 0.69191758, 1.37616285, 1.79926085,\n",
      "       0.14571842, 0.21536009, 0.68798256, 1.13798221, 1.66925581,\n",
      "       0.14372516, 0.19160533, 0.77496886, 1.45787279, 1.9584446 ,\n",
      "       0.14570022, 0.24605465, 0.82752093, 1.53301374, 1.76506623,\n",
      "       0.15603542, 0.24305447, 0.73983407, 1.34802421, 1.7085224 ,\n",
      "       0.14569934, 0.20831021, 0.69136175, 1.19590704, 1.48523355]), 'std_fit_time': array([4.73955360e-04, 8.57714127e-03, 7.11382218e-03, 5.44910496e-02,\n",
      "       3.87658291e-02, 5.25007848e-03, 2.86821321e-03, 1.18433123e-02,\n",
      "       3.64525572e-02, 5.92546188e-02, 2.94639065e-02, 4.03643178e-03,\n",
      "       4.32874270e-02, 2.88777579e-02, 1.01459898e-02, 2.16031107e-03,\n",
      "       2.48563334e-02, 4.50683357e-02, 9.00405780e-02, 5.49455575e-02,\n",
      "       2.82912128e-03, 5.12592231e-03, 6.29373062e-02, 7.36575185e-03,\n",
      "       7.96774635e-02, 0.00000000e+00, 7.36631381e-03, 3.37568377e-02,\n",
      "       7.02701844e-02, 4.41976580e-02, 4.68957217e-06, 7.36895635e-03,\n",
      "       3.21084888e-02, 3.75286804e-02, 4.45707698e-02, 7.36535847e-03,\n",
      "       1.94171555e-03, 1.11183620e-02, 6.22654711e-02, 2.49189787e-02,\n",
      "       1.24736239e-03, 1.85763163e-02, 2.75248321e-02, 4.10172741e-02,\n",
      "       2.55163942e-02, 4.32176626e-03, 1.38192988e-02, 5.68231294e-02,\n",
      "       2.84643588e-02, 9.50274163e-03, 5.16237080e-03, 7.36592042e-03,\n",
      "       2.20006999e-02, 7.36637000e-03, 3.93339320e-02, 4.49566384e-07,\n",
      "       1.47328524e-02, 4.87755478e-02, 1.94742719e-02, 9.57034798e-03,\n",
      "       3.68213176e-03, 9.18008554e-03, 2.54271496e-02, 2.38618995e-02,\n",
      "       7.08821887e-03, 2.49463978e-03, 3.59189685e-03, 5.60933334e-02,\n",
      "       9.89332692e-03, 4.62064761e-02, 6.83651389e-07, 6.55207254e-03,\n",
      "       7.32073796e-03, 7.91914277e-02, 2.27350187e-02, 3.18312388e-03,\n",
      "       1.13512837e-02, 2.45479391e-03, 1.13466243e-01, 6.51655645e-02,\n",
      "       1.33696874e-02, 1.49637743e-02, 6.49675019e-02, 1.01745676e-01,\n",
      "       8.63684308e-02, 6.64992660e-03, 9.13477315e-03, 4.08361793e-02,\n",
      "       1.25723784e-01, 8.98362448e-02, 3.50080927e-03, 1.05551528e-02,\n",
      "       4.81149401e-02, 9.90321191e-02, 1.02398364e-01, 3.60529010e-03,\n",
      "       7.74290580e-03, 1.32791024e-01, 3.38835880e-02, 1.94356737e-02,\n",
      "       1.56612148e-02, 1.32295006e-02, 3.89124367e-02, 2.29589715e-02,\n",
      "       3.02980102e-02, 2.94481376e-03, 1.69990853e-03, 4.30396999e-02,\n",
      "       1.06172388e-01, 2.82001888e-02, 1.70025135e-03, 7.76196789e-03,\n",
      "       2.33135447e-02, 3.29202048e-02, 1.02123028e-02, 1.09173642e-03,\n",
      "       4.54281214e-03, 2.33117572e-02, 2.59642217e-02, 5.13939076e-02,\n",
      "       2.16071574e-03, 1.21951977e-02, 1.08493791e-01, 3.52622231e-02,\n",
      "       1.62178689e-02, 3.63429966e-03, 1.92290160e-02, 6.32439557e-02,\n",
      "       3.37412882e-02, 3.53484382e-02, 4.37045961e-03, 2.41559716e-03,\n",
      "       3.39953988e-02, 2.17510594e-02, 2.74773641e-02, 4.49789440e-03,\n",
      "       5.10126843e-03, 5.68006857e-02, 4.64598168e-02, 2.26964229e-02,\n",
      "       9.80036352e-03, 2.82934604e-03, 1.36006080e-02, 7.21911313e-02,\n",
      "       8.95867793e-03, 3.09160771e-03, 4.35583968e-03, 2.36494236e-02,\n",
      "       2.24096386e-02, 2.40282001e-02]), 'mean_score_time': array([0.1135269 , 0.10469182, 0.11202629, 0.24618912, 0.21349541,\n",
      "       0.10535804, 0.10702395, 0.12500906, 0.14069859, 0.21171467,\n",
      "       0.12500842, 0.11714085, 0.10869082, 0.21004772, 0.21004748,\n",
      "       0.1136926 , 0.11235833, 0.11402535, 0.16146843, 0.23959899,\n",
      "       0.12004296, 0.12500938, 0.12500763, 0.22918256, 0.22918534,\n",
      "       0.13021636, 0.14063549, 0.11980025, 0.23959883, 0.23150102,\n",
      "       0.12500437, 0.12500882, 0.11980017, 0.20771408, 0.21687786,\n",
      "       0.12111759, 0.10602403, 0.10535741, 0.23439026, 0.21138128,\n",
      "       0.10876528, 0.12500763, 0.11968064, 0.20838086, 0.23439129,\n",
      "       0.10902437, 0.10502505, 0.11524757, 0.15854875, 0.22918248,\n",
      "       0.12500858, 0.1250085 , 0.11445125, 0.19041912, 0.20838078,\n",
      "       0.12500906, 0.12500882, 0.10802412, 0.21404791, 0.20971425,\n",
      "       0.10769049, 0.10835822, 0.1066912 , 0.15625985, 0.22058622,\n",
      "       0.11219716, 0.12500763, 0.11979961, 0.20904764, 0.21434665,\n",
      "       0.12144748, 0.10735758, 0.10740836, 0.22548366, 0.21504935,\n",
      "       0.10976036, 0.10769089, 0.11178327, 0.22297351, 0.21796783,\n",
      "       0.11302598, 0.14716395, 0.12495446, 0.21538258, 0.21627347,\n",
      "       0.11186488, 0.12706105, 0.11002525, 0.25539136, 0.22538487,\n",
      "       0.10995412, 0.11383486, 0.13303026, 0.21271539, 0.21764843,\n",
      "       0.12130817, 0.12102803, 0.12558333, 0.17570678, 0.20938071,\n",
      "       0.12246966, 0.10635742, 0.11069171, 0.22238358, 0.20838006,\n",
      "       0.10735782, 0.10669104, 0.11335889, 0.21473026, 0.22377038,\n",
      "       0.10835743, 0.10535781, 0.11258984, 0.24653721, 0.20938087,\n",
      "       0.11802737, 0.11918759, 0.11435906, 0.13969906, 0.22167317,\n",
      "       0.10669112, 0.10602403, 0.12890498, 0.23439066, 0.22120078,\n",
      "       0.11848966, 0.11969153, 0.12500827, 0.21425756, 0.2380538 ,\n",
      "       0.12007928, 0.11858312, 0.10702475, 0.22138405, 0.2137142 ,\n",
      "       0.11669254, 0.11535962, 0.11402607, 0.21671629, 0.21379058,\n",
      "       0.11069194, 0.10835743, 0.11102478, 0.23424164, 0.20771345,\n",
      "       0.10675947, 0.1223588 , 0.11233576, 0.10535741, 0.20704699]), 'std_score_time': array([4.75749945e-03, 4.71595499e-04, 3.56015266e-03, 8.51216833e-03,\n",
      "       4.31165945e-03, 4.71257962e-04, 8.16729421e-04, 0.00000000e+00,\n",
      "       4.83450289e-02, 2.49491591e-03, 5.61957980e-07, 7.86111779e-03,\n",
      "       1.24727744e-03, 8.16729839e-04, 2.82855930e-03, 4.49767052e-03,\n",
      "       4.71033823e-04, 5.71709192e-03, 5.15645337e-02, 7.36625760e-03,\n",
      "       1.41433584e-03, 2.24783192e-07, 1.27584404e-02, 7.36580804e-03,\n",
      "       1.47294813e-02, 7.36659477e-03, 1.94667955e-07, 7.36653858e-03,\n",
      "       7.36586428e-03, 4.08852529e-03, 4.78555972e-06, 5.15042996e-07,\n",
      "       7.36597662e-03, 4.71707529e-04, 1.23959016e-02, 5.50235538e-03,\n",
      "       8.16437471e-04, 4.71538951e-04, 1.94667955e-07, 9.42291322e-04,\n",
      "       2.15986962e-03, 6.74349576e-07, 1.48173644e-02, 9.43021732e-04,\n",
      "       4.89903609e-07, 1.63306948e-03, 1.94667955e-07, 7.84482786e-03,\n",
      "       4.74332996e-02, 7.36676336e-03, 5.15042996e-07, 2.97360213e-07,\n",
      "       7.46713196e-03, 4.80112838e-02, 1.88576242e-03, 7.01885292e-07,\n",
      "       3.37174788e-07, 5.15042996e-07, 3.56028657e-03, 2.35746992e-03,\n",
      "       4.71651423e-04, 9.43639840e-04, 2.35696417e-03, 4.41976580e-02,\n",
      "       7.51665667e-03, 7.36196814e-03, 3.37174788e-07, 7.36608902e-03,\n",
      "       1.41439207e-03, 2.62650815e-03, 5.03666080e-03, 4.71819960e-04,\n",
      "       2.40099466e-03, 2.08673816e-02, 4.24328852e-03, 4.44682475e-03,\n",
      "       4.71595177e-04, 4.09589276e-03, 1.47138573e-02, 1.08292061e-02,\n",
      "       8.16632263e-04, 4.80926439e-03, 6.77280391e-03, 4.71505224e-03,\n",
      "       8.41825360e-03, 4.66627248e-03, 1.12644477e-02, 2.94467906e-03,\n",
      "       4.42995976e-02, 1.32023036e-02, 3.46053660e-03, 7.52127519e-03,\n",
      "       1.55593240e-02, 2.35769471e-03, 5.37434147e-03, 7.27848345e-03,\n",
      "       7.25907452e-03, 4.73287093e-03, 4.93556258e-02, 1.24717123e-03,\n",
      "       7.38564515e-03, 4.71145731e-04, 3.68192309e-03, 1.04050687e-02,\n",
      "       1.24736239e-03, 9.42459734e-04, 1.70009569e-03, 4.11011079e-03,\n",
      "       4.48499403e-03, 5.51139228e-03, 1.24674641e-03, 4.71258123e-04,\n",
      "       6.60020558e-03, 1.23564639e-02, 1.24725623e-03, 6.99416289e-03,\n",
      "       8.21476360e-03, 4.19136373e-03, 4.76228480e-02, 1.01751446e-02,\n",
      "       4.71707529e-04, 3.89335909e-07, 7.71693081e-03, 4.05233662e-07,\n",
      "       3.44485862e-03, 4.61068388e-03, 4.72707804e-03, 4.89903609e-07,\n",
      "       2.16001676e-03, 2.38514631e-02, 6.97092016e-03, 1.03065316e-03,\n",
      "       2.82884028e-03, 3.85952731e-03, 1.88503189e-03, 8.01481332e-03,\n",
      "       3.85943796e-03, 4.89930578e-03, 5.18625403e-03, 5.36062588e-03,\n",
      "       4.11040731e-03, 4.71539032e-04, 4.32187296e-03, 1.80679662e-02,\n",
      "       9.42853179e-04, 1.04024046e-03, 4.07575601e-03, 3.49238005e-03,\n",
      "       4.71707569e-04, 1.63336155e-03]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 12,\n",
      "                   12, 12, 12, 12, 16, 16, 16, 16, 16, 2, 2, 2, 2, 2, 4,\n",
      "                   4, 4, 4, 4, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 16,\n",
      "                   16, 16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10,\n",
      "                   10, 10, 10, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16, 2,\n",
      "                   2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 12, 12,\n",
      "                   12, 12, 12, 16, 16, 16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4,\n",
      "                   4, 4, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 16, 16,\n",
      "                   16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10,\n",
      "                   10, 10, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700,\n",
      "                   1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000,\n",
      "                   50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700,\n",
      "                   1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000,\n",
      "                   50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}], 'split0_test_score': array([0.83653846, 0.81730769, 0.82692308, 0.82692308, 0.81730769,\n",
      "       0.83173077, 0.83653846, 0.85576923, 0.85576923, 0.85576923,\n",
      "       0.84615385, 0.84615385, 0.84615385, 0.84615385, 0.84134615,\n",
      "       0.84134615, 0.85096154, 0.84615385, 0.84615385, 0.84134615,\n",
      "       0.83173077, 0.82692308, 0.84615385, 0.84615385, 0.84615385,\n",
      "       0.84134615, 0.84134615, 0.85576923, 0.84615385, 0.84134615,\n",
      "       0.84134615, 0.84134615, 0.85576923, 0.84615385, 0.84134615,\n",
      "       0.84134615, 0.84134615, 0.85576923, 0.84615385, 0.84134615,\n",
      "       0.84134615, 0.84615385, 0.84134615, 0.84615385, 0.84615385,\n",
      "       0.85096154, 0.84615385, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.8125    , 0.8125    , 0.83173077, 0.82692308, 0.83173077,\n",
      "       0.8125    , 0.8125    , 0.83173077, 0.82692308, 0.83173077,\n",
      "       0.8125    , 0.8125    , 0.83173077, 0.82692308, 0.83173077,\n",
      "       0.8125    , 0.8125    , 0.83173077, 0.82692308, 0.83173077,\n",
      "       0.8125    , 0.8125    , 0.83173077, 0.82692308, 0.83173077,\n",
      "       0.81730769, 0.82211538, 0.82692308, 0.83173077, 0.82692308,\n",
      "       0.84615385, 0.85576923, 0.85576923, 0.86057692, 0.86057692,\n",
      "       0.84615385, 0.83653846, 0.83653846, 0.83653846, 0.84134615,\n",
      "       0.84134615, 0.84134615, 0.84615385, 0.84615385, 0.85096154,\n",
      "       0.84134615, 0.84134615, 0.85096154, 0.84134615, 0.84134615,\n",
      "       0.84615385, 0.84134615, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.84615385, 0.84134615, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.84615385, 0.84134615, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.84615385, 0.84134615, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.83653846, 0.83653846, 0.84134615, 0.83653846, 0.83653846,\n",
      "       0.82211538, 0.82211538, 0.83653846, 0.83653846, 0.83653846,\n",
      "       0.82211538, 0.82211538, 0.83653846, 0.83653846, 0.83653846,\n",
      "       0.82211538, 0.82211538, 0.83653846, 0.83653846, 0.83653846,\n",
      "       0.82211538, 0.82211538, 0.83653846, 0.83653846, 0.83653846,\n",
      "       0.82211538, 0.82211538, 0.83653846, 0.83653846, 0.83653846]), 'split1_test_score': array([0.82692308, 0.84134615, 0.84615385, 0.84134615, 0.84134615,\n",
      "       0.85096154, 0.85576923, 0.86538462, 0.85576923, 0.85576923,\n",
      "       0.82692308, 0.84615385, 0.83173077, 0.83173077, 0.83653846,\n",
      "       0.85096154, 0.84134615, 0.83653846, 0.83653846, 0.83653846,\n",
      "       0.83653846, 0.84134615, 0.83173077, 0.83653846, 0.84134615,\n",
      "       0.85096154, 0.84615385, 0.84615385, 0.83653846, 0.84134615,\n",
      "       0.85096154, 0.84615385, 0.84615385, 0.83653846, 0.84134615,\n",
      "       0.85096154, 0.84615385, 0.84615385, 0.83653846, 0.84134615,\n",
      "       0.84134615, 0.84615385, 0.84134615, 0.83173077, 0.84134615,\n",
      "       0.82692308, 0.84134615, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.82692308, 0.82692308, 0.83173077, 0.82211538, 0.82211538,\n",
      "       0.82692308, 0.82692308, 0.83173077, 0.82211538, 0.82211538,\n",
      "       0.82692308, 0.82692308, 0.83173077, 0.82211538, 0.82211538,\n",
      "       0.82692308, 0.82692308, 0.83173077, 0.82211538, 0.82211538,\n",
      "       0.82692308, 0.82692308, 0.83173077, 0.82211538, 0.82211538,\n",
      "       0.83173077, 0.84615385, 0.84615385, 0.84615385, 0.84615385,\n",
      "       0.84134615, 0.85576923, 0.86538462, 0.86057692, 0.86538462,\n",
      "       0.84615385, 0.84134615, 0.84134615, 0.84134615, 0.84615385,\n",
      "       0.83653846, 0.84134615, 0.83653846, 0.84615385, 0.84615385,\n",
      "       0.83653846, 0.84134615, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.84134615, 0.84615385, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.84134615, 0.84615385, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.84134615, 0.84615385, 0.84134615, 0.84134615, 0.84134615,\n",
      "       0.82692308, 0.84615385, 0.83653846, 0.83173077, 0.84134615,\n",
      "       0.83653846, 0.84134615, 0.84615385, 0.84615385, 0.84134615,\n",
      "       0.82692308, 0.82211538, 0.83173077, 0.82692308, 0.82211538,\n",
      "       0.82692308, 0.82211538, 0.83173077, 0.82692308, 0.82211538,\n",
      "       0.82692308, 0.82211538, 0.83173077, 0.82692308, 0.82211538,\n",
      "       0.82692308, 0.82211538, 0.83173077, 0.82692308, 0.82211538,\n",
      "       0.82692308, 0.82211538, 0.83173077, 0.82692308, 0.82211538]), 'split2_test_score': array([0.8115942 , 0.80676329, 0.8115942 , 0.80676329, 0.80676329,\n",
      "       0.80676329, 0.8115942 , 0.8115942 , 0.81642512, 0.81642512,\n",
      "       0.83091787, 0.82125604, 0.82125604, 0.81642512, 0.82125604,\n",
      "       0.82125604, 0.80676329, 0.81642512, 0.8115942 , 0.8115942 ,\n",
      "       0.81642512, 0.8115942 , 0.80676329, 0.80676329, 0.80676329,\n",
      "       0.79710145, 0.81642512, 0.80193237, 0.80676329, 0.80676329,\n",
      "       0.79710145, 0.81642512, 0.80193237, 0.80676329, 0.80676329,\n",
      "       0.79710145, 0.81642512, 0.80193237, 0.80676329, 0.80676329,\n",
      "       0.81642512, 0.83091787, 0.80676329, 0.81642512, 0.8115942 ,\n",
      "       0.82608696, 0.82608696, 0.81642512, 0.81642512, 0.81642512,\n",
      "       0.81642512, 0.8115942 , 0.80193237, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.8115942 , 0.80193237, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.8115942 , 0.80193237, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.8115942 , 0.80193237, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.8115942 , 0.80193237, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.80676329, 0.81642512, 0.8115942 , 0.8115942 ,\n",
      "       0.81642512, 0.8115942 , 0.80676329, 0.81642512, 0.82125604,\n",
      "       0.81642512, 0.81642512, 0.81642512, 0.81642512, 0.81642512,\n",
      "       0.82125604, 0.81642512, 0.81642512, 0.82125604, 0.82125604,\n",
      "       0.81642512, 0.82125604, 0.80676329, 0.81642512, 0.8115942 ,\n",
      "       0.80193237, 0.80193237, 0.80193237, 0.80193237, 0.80676329,\n",
      "       0.80193237, 0.80193237, 0.80193237, 0.80193237, 0.80676329,\n",
      "       0.80193237, 0.80193237, 0.80193237, 0.80193237, 0.80676329,\n",
      "       0.8115942 , 0.81642512, 0.80193237, 0.8115942 , 0.82608696,\n",
      "       0.82125604, 0.82125604, 0.8115942 , 0.8115942 , 0.81642512,\n",
      "       0.81642512, 0.8115942 , 0.79710145, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.8115942 , 0.79710145, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.8115942 , 0.79710145, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.8115942 , 0.79710145, 0.79710145, 0.79710145,\n",
      "       0.81642512, 0.8115942 , 0.79710145, 0.79710145, 0.79710145]), 'mean_test_score': array([0.82504013, 0.82182986, 0.8282504 , 0.82504013, 0.82182986,\n",
      "       0.82985554, 0.83467095, 0.84430177, 0.84269663, 0.84269663,\n",
      "       0.83467095, 0.83788122, 0.83306581, 0.83146067, 0.83306581,\n",
      "       0.83788122, 0.83306581, 0.83306581, 0.83146067, 0.82985554,\n",
      "       0.8282504 , 0.82664526, 0.8282504 , 0.82985554, 0.83146067,\n",
      "       0.82985554, 0.83467095, 0.83467095, 0.82985554, 0.82985554,\n",
      "       0.82985554, 0.83467095, 0.83467095, 0.82985554, 0.82985554,\n",
      "       0.82985554, 0.83467095, 0.83467095, 0.82985554, 0.82985554,\n",
      "       0.83306581, 0.84109149, 0.82985554, 0.83146067, 0.83306581,\n",
      "       0.83467095, 0.83788122, 0.83306581, 0.83306581, 0.83306581,\n",
      "       0.81861958, 0.81701445, 0.82182986, 0.81540931, 0.81701445,\n",
      "       0.81861958, 0.81701445, 0.82182986, 0.81540931, 0.81701445,\n",
      "       0.81861958, 0.81701445, 0.82182986, 0.81540931, 0.81701445,\n",
      "       0.81861958, 0.81701445, 0.82182986, 0.81540931, 0.81701445,\n",
      "       0.81861958, 0.81701445, 0.82182986, 0.81540931, 0.81701445,\n",
      "       0.82182986, 0.82504013, 0.82985554, 0.82985554, 0.8282504 ,\n",
      "       0.83467095, 0.84109149, 0.84269663, 0.8459069 , 0.84911717,\n",
      "       0.83627608, 0.83146067, 0.83146067, 0.83146067, 0.83467095,\n",
      "       0.83306581, 0.83306581, 0.83306581, 0.83788122, 0.83948636,\n",
      "       0.83146067, 0.83467095, 0.83306581, 0.83306581, 0.83146067,\n",
      "       0.82985554, 0.82985554, 0.8282504 , 0.8282504 , 0.82985554,\n",
      "       0.82985554, 0.82985554, 0.8282504 , 0.8282504 , 0.82985554,\n",
      "       0.82985554, 0.82985554, 0.8282504 , 0.8282504 , 0.82985554,\n",
      "       0.8282504 , 0.83467095, 0.82664526, 0.8282504 , 0.83627608,\n",
      "       0.83146067, 0.83306581, 0.83306581, 0.83146067, 0.83146067,\n",
      "       0.82182986, 0.81861958, 0.82182986, 0.82022472, 0.81861958,\n",
      "       0.82182986, 0.81861958, 0.82182986, 0.82022472, 0.81861958,\n",
      "       0.82182986, 0.81861958, 0.82182986, 0.82022472, 0.81861958,\n",
      "       0.82182986, 0.81861958, 0.82182986, 0.82022472, 0.81861958,\n",
      "       0.82182986, 0.81861958, 0.82182986, 0.82022472, 0.81861958]), 'std_test_score': array([0.01026625, 0.01447127, 0.01413448, 0.01417551, 0.01447127,\n",
      "       0.01808536, 0.01807551, 0.02340416, 0.01853205, 0.01853205,\n",
      "       0.00829126, 0.01172749, 0.01020424, 0.0121333 , 0.00855912,\n",
      "       0.01236802, 0.01896529, 0.01237839, 0.01455416, 0.01303054,\n",
      "       0.00856977, 0.01214287, 0.01626237, 0.01675644, 0.01753205,\n",
      "       0.02343652, 0.01301973, 0.02342573, 0.01675644, 0.01628939,\n",
      "       0.02343652, 0.01301973, 0.02342573, 0.01675644, 0.01628939,\n",
      "       0.02343652, 0.01301973, 0.02342573, 0.01675644, 0.01628939,\n",
      "       0.01173843, 0.00717652, 0.01628939, 0.0121333 , 0.01527302,\n",
      "       0.0115381 , 0.00854848, 0.01173843, 0.01173843, 0.01173843,\n",
      "       0.00609285, 0.00702463, 0.01403579, 0.01306299, 0.01458576,\n",
      "       0.00609285, 0.00702463, 0.01403579, 0.01306299, 0.01458576,\n",
      "       0.00609285, 0.00702463, 0.01403579, 0.01306299, 0.01458576,\n",
      "       0.00609285, 0.00702463, 0.01403579, 0.01306299, 0.01458576,\n",
      "       0.00609285, 0.00702463, 0.01403579, 0.01306299, 0.01458576,\n",
      "       0.00701868, 0.01620744, 0.01230815, 0.01416556, 0.01413448,\n",
      "       0.01301973, 0.02080753, 0.0256502 , 0.02079659, 0.0197513 ,\n",
      "       0.01400297, 0.01078652, 0.01078652, 0.01078652, 0.01301973,\n",
      "       0.00855912, 0.01173843, 0.01237839, 0.01172749, 0.01300891,\n",
      "       0.01078652, 0.00946294, 0.01896529, 0.01173843, 0.01401391,\n",
      "       0.01979485, 0.01979485, 0.01856487, 0.01856487, 0.01628939,\n",
      "       0.01979485, 0.01979485, 0.01856487, 0.01856487, 0.01628939,\n",
      "       0.01979485, 0.01979485, 0.01856487, 0.01856487, 0.01628939,\n",
      "       0.01413448, 0.01301973, 0.01754292, 0.01238877, 0.00718746,\n",
      "       0.0071984 , 0.00855912, 0.01527302, 0.01455416, 0.01078652,\n",
      "       0.00428881, 0.00495574, 0.01755379, 0.01677771, 0.01628277,\n",
      "       0.00428881, 0.00495574, 0.01755379, 0.01677771, 0.01628277,\n",
      "       0.00428881, 0.00495574, 0.01755379, 0.01677771, 0.01628277,\n",
      "       0.00428881, 0.00495574, 0.01755379, 0.01677771, 0.01628277,\n",
      "       0.00428881, 0.00495574, 0.01755379, 0.01677771, 0.01628277]), 'rank_test_score': array([ 95,  98,  81,  95,  98,  57,  16,   3,   4,   4,  16,  10,  29,\n",
      "        45,  29,  10,  29,  29,  45,  57,  81,  93,  81,  57,  45,  57,\n",
      "        16,  16,  57,  57,  57,  16,  16,  57,  57,  57,  16,  16,  57,\n",
      "        57,  29,   7,  57,  45,  29,  16,  10,  29,  29,  29, 121, 136,\n",
      "        98, 146, 136, 121, 136,  98, 146, 136, 121, 136,  98, 146, 136,\n",
      "       121, 136,  98, 146, 136, 121, 136,  98, 146, 136,  98,  95,  57,\n",
      "        57,  81,  16,   7,   4,   2,   1,  14,  45,  45,  45,  16,  29,\n",
      "        29,  29,  10,   9,  45,  16,  29,  29,  45,  57,  57,  81,  81,\n",
      "        57,  57,  57,  81,  81,  57,  57,  57,  81,  81,  57,  81,  16,\n",
      "        93,  81,  14,  45,  29,  29,  45,  45,  98, 121,  98, 116, 121,\n",
      "        98, 121,  98, 116, 121,  98, 121,  98, 116, 121,  98, 121,  98,\n",
      "       116, 121,  98, 121,  98, 116, 121])}\n"
     ]
    }
   ],
   "source": [
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So, we will set the best params and fit a Classifier\n",
    "\n",
    "* We also perform cross validation to see how it goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832      0.872      0.856      0.816      0.79674797]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_cross_val=RandomForestClassifier(max_features='auto', oob_score=True, random_state=SEED, n_jobs=-1,\n",
    "                              criterion='entropy',min_samples_leaf= 1, min_samples_split= 4, n_estimators= 1000)\n",
    "\n",
    "rf_cross_val_scores = cross_val_score(rf_cross_val, X_train, y_train, cv=5)\n",
    "\n",
    "print(rf_cross_val_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluating on X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(max_features='auto', oob_score=True, random_state=42, n_jobs=-1,\n",
    "                              criterion='entropy',min_samples_leaf= 1, min_samples_split= 4, n_estimators= 1000)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "predictions=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       165\n",
      "           1       0.79      0.70      0.74       102\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.79      0.80       267\n",
      "weighted avg       0.81      0.81      0.81       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146  19]\n",
      " [ 31  71]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC_AUC_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851455733808675\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba=rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "rf_roc_auc_score=roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "print(rf_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost ( Adaptive Boosting )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8154093097913323\n",
      "{'learning_rate': 0.01, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier(max_depth=1,random_state=SEED)\n",
    "\n",
    "adb_clf=AdaBoostClassifier(base_estimator=dt,random_state=SEED)\n",
    "\n",
    "param_grid = {'n_estimators':[10,20,50,100,200,500,1000,2000],'learning_rate':[.001,0.01,.1,1,10]}\n",
    "\n",
    "gs = GridSearchCV(estimator=adb_clf, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "#print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.808      0.848      0.808      0.816      0.80487805]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dt=DecisionTreeClassifier(max_depth=1,random_state=SEED)\n",
    "\n",
    "adb_clf_cross_val=AdaBoostClassifier(base_estimator=dt,n_estimators=1000,learning_rate=0.01,random_state=SEED)\n",
    "\n",
    "adb_cross_val_scores = cross_val_score(adb_clf_cross_val, X_train, y_train, cv=5)\n",
    "\n",
    "print(adb_cross_val_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluating on X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier(max_depth=1,random_state=SEED)\n",
    "\n",
    "adb_clf=AdaBoostClassifier(base_estimator=dt,n_estimators=1000,learning_rate=0.01)\n",
    "\n",
    "adb_clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "predictions=adb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       165\n",
      "           1       0.74      0.81      0.78       102\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.82      0.81       267\n",
      "weighted avg       0.83      0.82      0.82       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136  29]\n",
      " [ 19  83]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC_AUC_SCORE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8694592988710635\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba=adb_clf.predict_proba(X_test)[:,1]\n",
    "adb_clf_roc_auc_score=roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "print(adb_clf_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490016260162602\n",
      "{'colsample_bytree': 0.7, 'learning_rate': 0.05, 'n_estimators': 500, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "xgb_clf=xgb.XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,500,750,1000],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "gs =GridSearchCV(estimator = xgb_clf, \n",
    "                       param_grid = param_grid, \n",
    "                        iid=False,\n",
    "                       cv=5, verbose = False)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "#print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832      0.904      0.84       0.832      0.80487805]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_clf_cross_val=xgb.XGBClassifier(n_estimators=500,colsample_bytree=0.7,subsample=0.8,\n",
    "                                    learning_rate=0.05,random_state=SEED)\n",
    "\n",
    "xgb_cross_val_scores = cross_val_score(xgb_clf_cross_val, X_train, y_train, cv=5)\n",
    "\n",
    "print(xgb_cross_val_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluating on X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf=xgb.XGBClassifier(n_estimators=500,colsample_bytree=0.7,subsample=0.8,learning_rate=0.05)\n",
    "\n",
    "xgb_clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "predictions=xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       165\n",
      "           1       0.79      0.69      0.73       102\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.80      0.79      0.79       267\n",
      "weighted avg       0.81      0.81      0.81       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146  19]\n",
      " [ 32  70]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC_AUC_SCORE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475044563279857\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba=xgb_clf.predict_proba(X_test)[:,1]\n",
    "xgb_clf_roc_auc_score=roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "print(xgb_clf_roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826645264847512\n",
      "{'C': 5, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression()\n",
    "\n",
    "param_grid={'C':[0.001,0.1,1,2,5,7,9,10,20,50,100],'penalty':['l2','l2']}\n",
    "\n",
    "gs = GridSearchCV(estimator=lr, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "#print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.824      0.848      0.816      0.824      0.81300813]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_cross_val=LogisticRegression(C=5,penalty='l2')\n",
    "\n",
    "lr_cross_val_scores = cross_val_score(lr_cross_val, X_train, y_train, cv=5)\n",
    "\n",
    "print(lr_cross_val_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and Evaluating on X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(C=5,penalty='l2')\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "predictions=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86       165\n",
      "           1       0.77      0.80      0.78       102\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.82      0.83      0.82       267\n",
      "weighted avg       0.83      0.83      0.83       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140  25]\n",
      " [ 20  82]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC_AUC_SCORE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8693404634581104\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba=lr.predict_proba(X_test)[:,1]\n",
    "xgb_clf_roc_auc_score=roc_auc_score(y_test,y_pred_proba)\n",
    "\n",
    "print(xgb_clf_roc_auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
